{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e81a93cb",
   "metadata": {},
   "source": [
    "## Data Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2721b9",
   "metadata": {},
   "source": [
    "This file is the data scraping part of the project, submitted to Prof. Soong Moon Kang for MSIN0074 Network Analysis by SRN 22086573."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4cca02",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff29d94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tweepy, requests, time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1046492f",
   "metadata": {},
   "source": [
    "### Crypto Keyword Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfc82777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoinMarketCap API\n",
    "# 72d55327-0a66-4493-a3d2-79db51e7167d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8025c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'Accepts': 'application/json',\n",
    "    'X-CMC_PRO_API_KEY': '72d55327-0a66-4493-a3d2-79db51e7167d'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8f0718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://pro-api.coinmarketcap.com/v1/cryptocurrency/listings/latest'\n",
    "response = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7755d7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02948317",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_coins = []\n",
    "for coin in data['data']:\n",
    "    if len(top_coins) >= 100:\n",
    "        break\n",
    "    if coin['symbol'] not in ['USDT', 'USD', 'USDC', 'BUSD']:\n",
    "        top_coins.append(coin['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "843c41b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bitcoin',\n",
       " 'Ethereum',\n",
       " 'BNB',\n",
       " 'XRP',\n",
       " 'Cardano',\n",
       " 'Dogecoin',\n",
       " 'Polygon',\n",
       " 'Solana',\n",
       " 'Polkadot',\n",
       " 'Shiba Inu']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_coins[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f2c79e",
   "metadata": {},
   "source": [
    "### Twitter Data Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3262a697",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_keys = {\n",
    "   'API Key': 'ZozkuUE5LBha3mUYvqiCirMp1',\n",
    "    'API Secret':'zVCIS0FUAj41Ado22495Rb1WdFA8BawabPv0l2JIsYqPrC7PhG',\n",
    "    'Access token':'185887433-a7YvuFhqUFbfGrOKZ03MQSCvY5XHfNUDy6JWj9te',\n",
    "    'Access token secret':'x8otPQONb5SFueHizjc3STNm0hhkVLpLp6y0STo8yJUMs',\n",
    "    'Bearer token':'AAAAAAAAAAAAAAAAAAAAAMTecAEAAAAAkHFoxA2Dr3LpUIfii99R6LRk7ks%3DaQvcEwC7MMufbSfnrnO4r5ZqJvgOXpA64t9gs79nSER78kGinU'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c30df058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter API credentials\n",
    "consumer_key = dict_keys['API Key']; consumer_secret = dict_keys['API Secret']\n",
    "access_token = dict_keys['Access token']; access_token_secret = dict_keys['Access token secret']\n",
    "BEARER_TOKEN = dict_keys['Bearer token']\n",
    "\n",
    "# Authenticate with Twitter API\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5427fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the keywords to search\n",
    "keywords = top_coins\n",
    "\n",
    "# Define the number of tweets to retrieve\n",
    "num_tweets = 1000\n",
    "\n",
    "# Define the backup interval in seconds\n",
    "backup_interval = 300 # 5 minutes\n",
    "\n",
    "# Define the output CSV file path\n",
    "output_file = 'twitter.csv'\n",
    "\n",
    "# Create a counter to keep track of the number of tweets retrieved\n",
    "num_retrieved = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7fdc8f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 15:58:42\n",
      "Backup complete at 2023-03-17 15:58:54\n",
      "Backup complete at 2023-03-17 15:59:04\n",
      "Retrieved 1000 tweets for keyword 'Bitcoin'\n",
      "Backup complete at 2023-03-17 15:59:08\n",
      "Backup complete at 2023-03-17 15:59:15\n",
      "Backup complete at 2023-03-17 15:59:27\n",
      "Backup complete at 2023-03-17 15:59:42\n",
      "Retrieved 2000 tweets for keyword 'Ethereum'\n",
      "Backup complete at 2023-03-17 15:59:51\n",
      "Backup complete at 2023-03-17 15:59:57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 16:13:41\n",
      "Backup complete at 2023-03-17 16:13:54\n",
      "Backup complete at 2023-03-17 16:14:08\n",
      "Retrieved 3000 tweets for keyword 'BNB'\n",
      "Backup complete at 2023-03-17 16:14:08\n",
      "Retrieved 3149 tweets for keyword 'XRP'\n",
      "Backup complete at 2023-03-17 16:14:17\n",
      "Backup complete at 2023-03-17 16:14:24\n",
      "Backup complete at 2023-03-17 16:14:34\n",
      "Backup complete at 2023-03-17 16:14:43\n",
      "Retrieved 4149 tweets for keyword 'Cardano'\n",
      "Backup complete at 2023-03-17 16:14:51\n",
      "Backup complete at 2023-03-17 16:14:54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 16:28:42\n",
      "Backup complete at 2023-03-17 16:28:53\n",
      "Backup complete at 2023-03-17 16:29:05\n",
      "Retrieved 5149 tweets for keyword 'Polygon'\n",
      "Backup complete at 2023-03-17 16:29:06\n",
      "Backup complete at 2023-03-17 16:29:16\n",
      "Backup complete at 2023-03-17 16:29:28\n",
      "Backup complete at 2023-03-17 16:29:40\n",
      "Retrieved 6149 tweets for keyword 'Dogecoin'\n",
      "Backup complete at 2023-03-17 16:29:45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 16:29:52\n",
      "Backup complete at 2023-03-17 16:43:46\n",
      "Backup complete at 2023-03-17 16:43:59\n",
      "Retrieved 7149 tweets for keyword 'Solana'\n",
      "Backup complete at 2023-03-17 16:44:09\n",
      "Backup complete at 2023-03-17 16:44:10\n",
      "Backup complete at 2023-03-17 16:44:20\n",
      "Backup complete at 2023-03-17 16:44:30\n",
      "Backup complete at 2023-03-17 16:44:38\n",
      "Retrieved 8149 tweets for keyword 'Polkadot'\n",
      "Backup complete at 2023-03-17 16:44:40\n",
      "Backup complete at 2023-03-17 16:44:48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 16:58:40\n",
      "Backup complete at 2023-03-17 16:58:50\n",
      "Retrieved 9149 tweets for keyword 'Shiba Inu'\n",
      "Backup complete at 2023-03-17 16:58:56\n",
      "Backup complete at 2023-03-17 16:59:04\n",
      "Backup complete at 2023-03-17 16:59:18\n",
      "Backup complete at 2023-03-17 16:59:31\n",
      "Retrieved 10149 tweets for keyword 'TRON'\n",
      "Backup complete at 2023-03-17 16:59:42\n",
      "Backup complete at 2023-03-17 16:59:46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 17:13:37\n",
      "Retrieved 10511 tweets for keyword 'Litecoin'\n",
      "Backup complete at 2023-03-17 17:13:38\n",
      "Backup complete at 2023-03-17 17:13:47\n",
      "Backup complete at 2023-03-17 17:13:57\n",
      "Backup complete at 2023-03-17 17:14:07\n",
      "Retrieved 11511 tweets for keyword 'Dai'\n",
      "Backup complete at 2023-03-17 17:14:11\n",
      "Backup complete at 2023-03-17 17:14:17\n",
      "Backup complete at 2023-03-17 17:14:28\n",
      "Backup complete at 2023-03-17 17:14:37\n",
      "Retrieved 12511 tweets for keyword 'Avalanche'\n",
      "Backup complete at 2023-03-17 17:14:43\n",
      "Backup complete at 2023-03-17 17:14:47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 17:28:38\n",
      "Backup complete at 2023-03-17 17:28:52\n",
      "Backup complete at 2023-03-17 17:29:05\n",
      "Retrieved 13511 tweets for keyword 'Uniswap'\n",
      "Backup complete at 2023-03-17 17:29:06\n",
      "Retrieved 13569 tweets for keyword 'Wrapped Bitcoin'\n",
      "Backup complete at 2023-03-17 17:29:11\n",
      "Backup complete at 2023-03-17 17:29:20\n",
      "Backup complete at 2023-03-17 17:29:31\n",
      "Backup complete at 2023-03-17 17:29:42\n",
      "Retrieved 14569 tweets for keyword 'Cosmos'\n",
      "Backup complete at 2023-03-17 17:29:48\n",
      "Backup complete at 2023-03-17 17:29:52\n",
      "Backup complete at 2023-03-17 17:30:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 17:43:39\n",
      "Retrieved 15569 tweets for keyword 'Chainlink'\n",
      "Backup complete at 2023-03-17 17:43:48\n",
      "Backup complete at 2023-03-17 17:43:50\n",
      "Retrieved 15707 tweets for keyword 'UNUS SED LEO'\n",
      "Backup complete at 2023-03-17 17:43:53\n",
      "Backup complete at 2023-03-17 17:43:59\n",
      "Backup complete at 2023-03-17 17:44:08\n",
      "Retrieved 16363 tweets for keyword 'Toncoin'\n",
      "Backup complete at 2023-03-17 17:44:13\n",
      "Backup complete at 2023-03-17 17:44:18\n",
      "Backup complete at 2023-03-17 17:44:29\n",
      "Backup complete at 2023-03-17 17:44:38\n",
      "Retrieved 17363 tweets for keyword 'OKB'\n",
      "Backup complete at 2023-03-17 17:44:47\n",
      "Backup complete at 2023-03-17 17:44:48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 17:58:42\n",
      "Backup complete at 2023-03-17 17:58:52\n",
      "Backup complete at 2023-03-17 17:59:05\n",
      "Retrieved 18363 tweets for keyword 'Monero'\n",
      "Backup complete at 2023-03-17 17:59:07\n",
      "Backup complete at 2023-03-17 17:59:15\n",
      "Backup complete at 2023-03-17 17:59:24\n",
      "Backup complete at 2023-03-17 17:59:33\n",
      "Retrieved 19270 tweets for keyword 'Ethereum Classic'\n",
      "Backup complete at 2023-03-17 17:59:35\n",
      "Retrieved 19369 tweets for keyword 'Bitcoin Cash'\n",
      "Backup complete at 2023-03-17 17:59:39\n",
      "Backup complete at 2023-03-17 17:59:43\n",
      "Backup complete at 2023-03-17 17:59:52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 18:13:45\n",
      "Retrieved 20369 tweets for keyword 'Filecoin'\n",
      "Backup complete at 2023-03-17 18:13:56\n",
      "Backup complete at 2023-03-17 18:13:58\n",
      "Backup complete at 2023-03-17 18:14:15\n",
      "Backup complete at 2023-03-17 18:14:30\n",
      "Backup complete at 2023-03-17 18:14:43\n",
      "Retrieved 21369 tweets for keyword 'Aptos'\n",
      "Backup complete at 2023-03-17 18:14:47\n",
      "Backup complete at 2023-03-17 18:14:55\n",
      "Backup complete at 2023-03-17 18:15:08\n",
      "Backup complete at 2023-03-17 18:15:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 22369 tweets for keyword 'Stellar'\n",
      "Backup complete at 2023-03-17 18:28:47\n",
      "Backup complete at 2023-03-17 18:28:51\n",
      "Backup complete at 2023-03-17 18:29:00\n",
      "Retrieved 23009 tweets for keyword 'Lido DAO'\n",
      "Backup complete at 2023-03-17 18:29:08\n",
      "Backup complete at 2023-03-17 18:29:12\n",
      "Backup complete at 2023-03-17 18:29:22\n",
      "Backup complete at 2023-03-17 18:29:31\n",
      "Retrieved 23878 tweets for keyword 'TrueUSD'\n",
      "Backup complete at 2023-03-17 18:29:37\n",
      "Backup complete at 2023-03-17 18:29:43\n",
      "Backup complete at 2023-03-17 18:29:54\n",
      "Backup complete at 2023-03-17 18:30:06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 24878 tweets for keyword 'Cronos'\n",
      "Backup complete at 2023-03-17 18:43:50\n",
      "Backup complete at 2023-03-17 18:43:51\n",
      "Backup complete at 2023-03-17 18:44:02\n",
      "Backup complete at 2023-03-17 18:44:13\n",
      "Backup complete at 2023-03-17 18:44:24\n",
      "Retrieved 25878 tweets for keyword 'NEAR Protocol'\n",
      "Backup complete at 2023-03-17 18:44:27\n",
      "Backup complete at 2023-03-17 18:44:36\n",
      "Backup complete at 2023-03-17 18:44:47\n",
      "Backup complete at 2023-03-17 18:44:58\n",
      "Retrieved 26878 tweets for keyword 'Hedera'\n",
      "Backup complete at 2023-03-17 18:45:05\n",
      "Backup complete at 2023-03-17 18:45:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 18:58:48\n",
      "Backup complete at 2023-03-17 18:59:00\n",
      "Retrieved 27878 tweets for keyword 'VeChain'\n",
      "Backup complete at 2023-03-17 18:59:10\n",
      "Backup complete at 2023-03-17 18:59:11\n",
      "Backup complete at 2023-03-17 18:59:20\n",
      "Backup complete at 2023-03-17 18:59:30\n",
      "Backup complete at 2023-03-17 18:59:40\n",
      "Retrieved 28878 tweets for keyword 'Internet Computer'\n",
      "Backup complete at 2023-03-17 18:59:42\n",
      "Retrieved 29020 tweets for keyword 'ApeCoin'\n",
      "Backup complete at 2023-03-17 18:59:51\n",
      "Backup complete at 2023-03-17 18:59:53\n",
      "Backup complete at 2023-03-17 19:00:04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 19:13:46\n",
      "Backup complete at 2023-03-17 19:13:57\n",
      "Retrieved 30020 tweets for keyword 'Quant'\n",
      "Backup complete at 2023-03-17 19:13:58\n",
      "Backup complete at 2023-03-17 19:14:08\n",
      "Backup complete at 2023-03-17 19:14:18\n",
      "Backup complete at 2023-03-17 19:14:28\n",
      "Retrieved 31020 tweets for keyword 'Algorand'\n",
      "Backup complete at 2023-03-17 19:14:32\n",
      "Backup complete at 2023-03-17 19:14:38\n",
      "Backup complete at 2023-03-17 19:14:49\n",
      "Backup complete at 2023-03-17 19:14:58\n",
      "Retrieved 32020 tweets for keyword 'Stacks'\n",
      "Backup complete at 2023-03-17 19:15:07\n",
      "Backup complete at 2023-03-17 19:15:11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 19:28:54\n",
      "Backup complete at 2023-03-17 19:29:09\n",
      "Backup complete at 2023-03-17 19:29:22\n",
      "Retrieved 33020 tweets for keyword 'The Graph'\n",
      "Backup complete at 2023-03-17 19:29:24\n",
      "Backup complete at 2023-03-17 19:29:33\n",
      "Backup complete at 2023-03-17 19:29:46\n",
      "Backup complete at 2023-03-17 19:29:57\n",
      "Retrieved 34020 tweets for keyword 'Fantom'\n",
      "Backup complete at 2023-03-17 19:30:03\n",
      "Backup complete at 2023-03-17 19:30:11\n",
      "Backup complete at 2023-03-17 19:30:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 19:43:53\n",
      "Retrieved 34844 tweets for keyword 'Immutable'\n",
      "Backup complete at 2023-03-17 19:43:55\n",
      "Backup complete at 2023-03-17 19:44:03\n",
      "Backup complete at 2023-03-17 19:44:13\n",
      "Backup complete at 2023-03-17 19:44:21\n",
      "Retrieved 35844 tweets for keyword 'EOS'\n",
      "Backup complete at 2023-03-17 19:44:26\n",
      "Backup complete at 2023-03-17 19:44:32\n",
      "Backup complete at 2023-03-17 19:44:41\n",
      "Backup complete at 2023-03-17 19:44:50\n",
      "Retrieved 36844 tweets for keyword 'BitDAO'\n",
      "Backup complete at 2023-03-17 19:44:58\n",
      "Backup complete at 2023-03-17 19:45:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 19:58:53\n",
      "Backup complete at 2023-03-17 19:59:04\n",
      "Backup complete at 2023-03-17 19:59:16\n",
      "Retrieved 37844 tweets for keyword 'Tezos'\n",
      "Backup complete at 2023-03-17 19:59:18\n",
      "Backup complete at 2023-03-17 19:59:27\n",
      "Backup complete at 2023-03-17 19:59:37\n",
      "Backup complete at 2023-03-17 19:59:47\n",
      "Retrieved 38844 tweets for keyword 'Decentraland'\n",
      "Backup complete at 2023-03-17 19:59:53\n",
      "Backup complete at 2023-03-17 19:59:58\n",
      "Backup complete at 2023-03-17 20:00:08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 20:13:55\n",
      "Retrieved 39844 tweets for keyword 'Aave'\n",
      "Backup complete at 2023-03-17 20:14:03\n",
      "Backup complete at 2023-03-17 20:14:05\n",
      "Backup complete at 2023-03-17 20:14:13\n",
      "Backup complete at 2023-03-17 20:14:21\n",
      "Backup complete at 2023-03-17 20:14:30\n",
      "Retrieved 40844 tweets for keyword 'Flow'\n",
      "Backup complete at 2023-03-17 20:14:32\n",
      "Backup complete at 2023-03-17 20:14:42\n",
      "Backup complete at 2023-03-17 20:14:56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 20:28:51\n",
      "Retrieved 41844 tweets for keyword 'MultiversX'\n",
      "Backup complete at 2023-03-17 20:28:57\n",
      "Backup complete at 2023-03-17 20:29:01\n",
      "Backup complete at 2023-03-17 20:29:09\n",
      "Backup complete at 2023-03-17 20:29:18\n",
      "Retrieved 42844 tweets for keyword 'Theta Network'\n",
      "Backup complete at 2023-03-17 20:29:25\n",
      "Backup complete at 2023-03-17 20:29:27\n",
      "Backup complete at 2023-03-17 20:29:35\n",
      "Backup complete at 2023-03-17 20:29:47\n",
      "Backup complete at 2023-03-17 20:29:57\n",
      "Retrieved 43844 tweets for keyword 'Axie Infinity'\n",
      "Backup complete at 2023-03-17 20:30:00\n",
      "Backup complete at 2023-03-17 20:30:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 20:43:57\n",
      "Backup complete at 2023-03-17 20:44:07\n",
      "Retrieved 44844 tweets for keyword 'The Sandbox'\n",
      "Backup complete at 2023-03-17 20:44:13\n",
      "Backup complete at 2023-03-17 20:44:19\n",
      "Backup complete at 2023-03-17 20:44:30\n",
      "Backup complete at 2023-03-17 20:44:42\n",
      "Retrieved 45844 tweets for keyword 'Conflux'\n",
      "Backup complete at 2023-03-17 20:44:50\n",
      "Backup complete at 2023-03-17 20:44:53\n",
      "Backup complete at 2023-03-17 20:45:04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 20:58:53\n",
      "Backup complete at 2023-03-17 20:59:02\n",
      "Retrieved 46844 tweets for keyword 'KuCoin Token'\n",
      "Backup complete at 2023-03-17 20:59:04\n",
      "Retrieved 46999 tweets for keyword 'Pax Dollar'\n",
      "Backup complete at 2023-03-17 20:59:09\n",
      "Backup complete at 2023-03-17 20:59:12\n",
      "Backup complete at 2023-03-17 20:59:23\n",
      "Backup complete at 2023-03-17 20:59:33\n",
      "Retrieved 47999 tweets for keyword 'Neo'\n",
      "Backup complete at 2023-03-17 20:59:42\n",
      "Backup complete at 2023-03-17 20:59:43\n",
      "Backup complete at 2023-03-17 20:59:53\n",
      "Backup complete at 2023-03-17 21:00:04\n",
      "Backup complete at 2023-03-17 21:00:13\n",
      "Retrieved 48999 tweets for keyword 'Optimism'\n",
      "Backup complete at 2023-03-17 21:00:18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 813\n"
     ]
    },
    {
     "ename": "TweepyException",
     "evalue": "Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 60] Operation timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    498\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m                 )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    787\u001b[0m             retries = retries.increment(\n\u001b[0;32m--> 788\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_method_retryable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    769\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    709\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_raise_timeout\u001b[0;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[1;32m    357\u001b[0m             raise ReadTimeoutError(\n\u001b[0;32m--> 358\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Read timed out. (read timeout=%s)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m             )\n",
      "\u001b[0;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tweepy/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m                         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpost_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson_payload\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m                     )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReadTimeoutError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mReadTimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_InvalidHeader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mReadTimeout\u001b[0m: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTweepyException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0p/z78rsq817mg13m26y_16h4pm0000gn/T/ipykernel_49785/1442339870.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msearch_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_tweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'extended'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_tweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msearch_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Extract the tweet data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         tweet_data = {\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;31m# Reached end of current page, get the next page...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRawParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             model = ModelParser().parse(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tweepy/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpagination_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tweepy/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'payload_list'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'payload_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpayload_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpayload_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tweepy/api.py\u001b[0m in \u001b[0;36msearch_tweets\u001b[0;34m(self, q, **kwargs)\u001b[0m\n\u001b[1;32m   1311\u001b[0m                 \u001b[0;34m'q'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'geocode'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lang'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'locale'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'result_type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m                 \u001b[0;34m'until'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'since_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'include_entities'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1313\u001b[0;31m             ), q=q, **kwargs\n\u001b[0m\u001b[1;32m   1314\u001b[0m         )\n\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tweepy/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m                     )\n\u001b[1;32m    227\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTweepyException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Failed to send request: {e}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/tweepy/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m                         \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpost_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson_payload\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m                     )\n\u001b[1;32m    227\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    585\u001b[0m         }\n\u001b[1;32m    586\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    576\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReadTimeoutError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mReadTimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_InvalidHeader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTweepyException\u001b[0m: Failed to send request: HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=60)"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store the tweets\n",
    "tweets = []\n",
    "\n",
    "# Loop through each keyword and get the tweets\n",
    "for keyword in keywords:\n",
    "    search_results = tweepy.Cursor(api.search_tweets, q=keyword, tweet_mode='extended').items(num_tweets)\n",
    "    for tweet in search_results:\n",
    "        # Extract the tweet data\n",
    "        tweet_data = {\n",
    "            'id': tweet.id,\n",
    "            'text': tweet.full_text,\n",
    "            'user_id': tweet.user.id,\n",
    "            'timestamp': tweet.created_at,\n",
    "            'retweet_count': tweet.retweet_count,\n",
    "            'favorite_count': tweet.favorite_count,\n",
    "            'in_reply_to_user_id': tweet.in_reply_to_user_id,\n",
    "            'twt_hashtags' : tweet.entities['hashtags'],\n",
    "            'user_id': tweet.user.id,\n",
    "            'user_name': tweet.user.name,\n",
    "            'followers_count': tweet.user.followers_count,\n",
    "            'friends_count': tweet.user.friends_count\n",
    "        }\n",
    "        # Append the tweet data to the list of tweets\n",
    "        tweets.append(tweet_data)\n",
    "        num_retrieved += 1\n",
    "        # Backup the data to a CSV file every backup_interval tweets\n",
    "        if num_retrieved % backup_interval == 0:\n",
    "            df = pd.DataFrame(tweets)\n",
    "            df.to_csv(output_file, index=False)\n",
    "            print(f\"Backup complete at {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Retrieved {num_retrieved} tweets for keyword '{keyword}'\")\n",
    "    # Backup the data to a CSV file after all tweets for a keyword have been retrieved\n",
    "    df = pd.DataFrame(tweets)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Backup complete at {time.strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5fce655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the keywords to search\n",
    "keywords = top_coins[56:]\n",
    "\n",
    "# Define the number of tweets to retrieve\n",
    "num_tweets = 1000\n",
    "\n",
    "# Define the backup interval in seconds\n",
    "backup_interval = 300 # 5 minutes\n",
    "\n",
    "# Define the output CSV file path\n",
    "output_file = 'twitter_56.csv'\n",
    "\n",
    "# Create a counter to keep track of the number of tweets retrieved\n",
    "num_retrieved = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03bd7691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 21:28:14\n",
      "Backup complete at 2023-03-17 21:28:22\n",
      "Backup complete at 2023-03-17 21:28:30\n",
      "Retrieved 1000 tweets for keyword 'Chiliz'\n",
      "Backup complete at 2023-03-17 21:28:33\n",
      "Backup complete at 2023-03-17 21:28:38\n",
      "Backup complete at 2023-03-17 21:28:46\n",
      "Backup complete at 2023-03-17 21:28:56\n",
      "Retrieved 2000 tweets for keyword 'Rocket Pool'\n",
      "Backup complete at 2023-03-17 21:29:01\n",
      "Backup complete at 2023-03-17 21:29:04\n",
      "Backup complete at 2023-03-17 21:29:11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 21:43:09\n",
      "Backup complete at 2023-03-17 21:43:16\n",
      "Retrieved 3000 tweets for keyword 'Terra Classic'\n",
      "Backup complete at 2023-03-17 21:43:16\n",
      "Backup complete at 2023-03-17 21:43:23\n",
      "Backup complete at 2023-03-17 21:43:30\n",
      "Backup complete at 2023-03-17 21:43:37\n",
      "Retrieved 4000 tweets for keyword 'Mina'\n",
      "Backup complete at 2023-03-17 21:43:39\n",
      "Backup complete at 2023-03-17 21:43:44\n",
      "Backup complete at 2023-03-17 21:43:51\n",
      "Backup complete at 2023-03-17 21:43:59\n",
      "Retrieved 5000 tweets for keyword 'Synthetix'\n",
      "Backup complete at 2023-03-17 21:44:05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 21:58:10\n",
      "Backup complete at 2023-03-17 21:58:16\n",
      "Backup complete at 2023-03-17 21:58:24\n",
      "Backup complete at 2023-03-17 21:58:31\n",
      "Retrieved 6000 tweets for keyword 'Klaytn'\n",
      "Backup complete at 2023-03-17 21:58:31\n",
      "Backup complete at 2023-03-17 21:58:42\n",
      "Backup complete at 2023-03-17 21:58:48\n",
      "Backup complete at 2023-03-17 21:58:55\n",
      "Retrieved 7000 tweets for keyword 'USDD'\n",
      "Backup complete at 2023-03-17 21:58:57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 22:13:11\n",
      "Backup complete at 2023-03-17 22:13:28\n",
      "Backup complete at 2023-03-17 22:13:45\n",
      "Retrieved 8000 tweets for keyword 'PancakeSwap'\n",
      "Backup complete at 2023-03-17 22:13:56\n",
      "Retrieved 8081 tweets for keyword 'Curve DAO Token'\n",
      "Backup complete at 2023-03-17 22:13:58\n",
      "Backup complete at 2023-03-17 22:13:59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 22:28:15\n",
      "Backup complete at 2023-03-17 22:28:25\n",
      "Backup complete at 2023-03-17 22:28:35\n",
      "Retrieved 9081 tweets for keyword 'Maker'\n",
      "Backup complete at 2023-03-17 22:28:38\n",
      "Backup complete at 2023-03-17 22:28:45\n",
      "Backup complete at 2023-03-17 22:28:55\n",
      "Backup complete at 2023-03-17 22:29:06\n",
      "Retrieved 9982 tweets for keyword 'Bitcoin SV'\n",
      "Backup complete at 2023-03-17 22:29:09\n",
      "Backup complete at 2023-03-17 22:29:16\n",
      "Backup complete at 2023-03-17 22:29:27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 22:43:15\n",
      "Retrieved 10982 tweets for keyword 'GMX'\n",
      "Backup complete at 2023-03-17 22:43:22\n",
      "Retrieved 10982 tweets for keyword 'Huobi Token'\n",
      "Backup complete at 2023-03-17 22:43:23\n",
      "Backup complete at 2023-03-17 22:43:28\n",
      "Backup complete at 2023-03-17 22:43:39\n",
      "Backup complete at 2023-03-17 22:43:49\n",
      "Retrieved 11982 tweets for keyword 'SingularityNET'\n",
      "Backup complete at 2023-03-17 22:44:00\n",
      "Backup complete at 2023-03-17 22:44:02\n",
      "Retrieved 12000 tweets for keyword 'BitTorrent-New'\n",
      "Backup complete at 2023-03-17 22:44:03\n",
      "Retrieved 12187 tweets for keyword 'Frax Share'\n",
      "Backup complete at 2023-03-17 22:44:10\n",
      "Backup complete at 2023-03-17 22:44:15\n",
      "Backup complete at 2023-03-17 22:44:25\n",
      "Backup complete at 2023-03-17 22:44:35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 13187 tweets for keyword 'Dash'\n",
      "Backup complete at 2023-03-17 22:58:14\n",
      "Backup complete at 2023-03-17 22:58:15\n",
      "Backup complete at 2023-03-17 22:58:26\n",
      "Backup complete at 2023-03-17 22:58:37\n",
      "Backup complete at 2023-03-17 22:58:48\n",
      "Retrieved 14187 tweets for keyword 'IOTA'\n",
      "Backup complete at 2023-03-17 22:58:51\n",
      "Backup complete at 2023-03-17 22:59:00\n",
      "Backup complete at 2023-03-17 22:59:11\n",
      "Backup complete at 2023-03-17 22:59:22\n",
      "Retrieved 15187 tweets for keyword 'Gemini Dollar'\n",
      "Backup complete at 2023-03-17 22:59:28\n",
      "Backup complete at 2023-03-17 22:59:32\n",
      "Backup complete at 2023-03-17 22:59:43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 23:13:18\n",
      "Retrieved 16187 tweets for keyword 'eCash'\n",
      "Backup complete at 2023-03-17 23:13:26\n",
      "Backup complete at 2023-03-17 23:13:27\n",
      "Retrieved 16282 tweets for keyword 'GateToken'\n",
      "Backup complete at 2023-03-17 23:13:29\n",
      "Backup complete at 2023-03-17 23:13:36\n",
      "Backup complete at 2023-03-17 23:13:46\n",
      "Backup complete at 2023-03-17 23:13:55\n",
      "Retrieved 17282 tweets for keyword 'Zcash'\n",
      "Backup complete at 2023-03-17 23:14:00\n",
      "Backup complete at 2023-03-17 23:14:04\n",
      "Backup complete at 2023-03-17 23:14:12\n",
      "Retrieved 17833 tweets for keyword 'PAX Gold'\n",
      "Backup complete at 2023-03-17 23:14:16\n",
      "Backup complete at 2023-03-17 23:14:23\n",
      "Backup complete at 2023-03-17 23:14:31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 18496 tweets for keyword 'Trust Wallet Token'\n",
      "Backup complete at 2023-03-17 23:28:22\n",
      "Backup complete at 2023-03-17 23:28:26\n",
      "Backup complete at 2023-03-17 23:28:36\n",
      "Backup complete at 2023-03-17 23:28:46\n",
      "Retrieved 19472 tweets for keyword 'Render Token'\n",
      "Backup complete at 2023-03-17 23:28:55\n",
      "Backup complete at 2023-03-17 23:28:56\n",
      "Backup complete at 2023-03-17 23:29:08\n",
      "Backup complete at 2023-03-17 23:29:20\n",
      "Backup complete at 2023-03-17 23:29:30\n",
      "Retrieved 20472 tweets for keyword 'THORChain'\n",
      "Backup complete at 2023-03-17 23:29:33\n",
      "Backup complete at 2023-03-17 23:29:41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-17 23:43:20\n",
      "Backup complete at 2023-03-17 23:43:31\n",
      "Retrieved 21472 tweets for keyword 'XDC Network'\n",
      "Backup complete at 2023-03-17 23:43:37\n",
      "Backup complete at 2023-03-17 23:43:41\n",
      "Backup complete at 2023-03-17 23:43:51\n",
      "Backup complete at 2023-03-17 23:44:02\n",
      "Retrieved 22472 tweets for keyword 'Kava'\n",
      "Backup complete at 2023-03-17 23:44:12\n",
      "Backup complete at 2023-03-17 23:44:14\n",
      "Backup complete at 2023-03-17 23:44:24\n",
      "Backup complete at 2023-03-17 23:44:35\n",
      "Backup complete at 2023-03-17 23:44:46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 23472 tweets for keyword 'Zilliqa'\n",
      "Backup complete at 2023-03-17 23:58:18\n",
      "Backup complete at 2023-03-17 23:58:26\n",
      "Backup complete at 2023-03-17 23:58:35\n",
      "Backup complete at 2023-03-17 23:58:44\n",
      "Retrieved 24472 tweets for keyword 'Loopring'\n",
      "Backup complete at 2023-03-17 23:58:49\n",
      "Backup complete at 2023-03-17 23:58:54\n",
      "Backup complete at 2023-03-17 23:59:04\n",
      "Backup complete at 2023-03-17 23:59:13\n",
      "Retrieved 25472 tweets for keyword 'Osmosis'\n",
      "Backup complete at 2023-03-17 23:59:21\n",
      "Backup complete at 2023-03-17 23:59:23\n",
      "Retrieved 25652 tweets for keyword '1inch Network'\n",
      "Backup complete at 2023-03-17 23:59:29\n",
      "Retrieved 25744 tweets for keyword 'Fei USD'\n",
      "Backup complete at 2023-03-17 23:59:33\n",
      "Backup complete at 2023-03-17 23:59:35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 25967 tweets for keyword 'Enjin Coin'\n",
      "Backup complete at 2023-03-18 00:13:22\n",
      "Backup complete at 2023-03-18 00:13:27\n",
      "Retrieved 26109 tweets for keyword 'Convex Finance'\n",
      "Backup complete at 2023-03-18 00:13:28\n",
      "Backup complete at 2023-03-18 00:13:36\n",
      "Backup complete at 2023-03-18 00:13:44\n",
      "Backup complete at 2023-03-18 00:13:52\n",
      "Retrieved 27109 tweets for keyword 'Casper'\n",
      "Backup complete at 2023-03-18 00:13:55\n",
      "Backup complete at 2023-03-18 00:14:01\n",
      "Backup complete at 2023-03-18 00:14:10\n",
      "Backup complete at 2023-03-18 00:14:17\n",
      "Retrieved 28109 tweets for keyword 'dYdX'\n",
      "Backup complete at 2023-03-18 00:14:23\n",
      "Backup complete at 2023-03-18 00:14:26\n",
      "Retrieved 28287 tweets for keyword 'ssv.network'\n",
      "Backup complete at 2023-03-18 00:14:29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rate limit reached. Sleeping for: 828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backup complete at 2023-03-18 00:28:26\n",
      "Backup complete at 2023-03-18 00:28:37\n",
      "Retrieved 28913 tweets for keyword 'WOO Network'\n",
      "Backup complete at 2023-03-18 00:28:43\n",
      "Backup complete at 2023-03-18 00:28:50\n",
      "Backup complete at 2023-03-18 00:29:00\n",
      "Backup complete at 2023-03-18 00:29:11\n",
      "Retrieved 29913 tweets for keyword 'Threshold'\n",
      "Backup complete at 2023-03-18 00:29:18\n",
      "Backup complete at 2023-03-18 00:29:21\n",
      "Retrieved 30066 tweets for keyword 'Basic Attention Token'\n",
      "Backup complete at 2023-03-18 00:29:25\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store the tweets\n",
    "tweets = []\n",
    "\n",
    "# Loop through each keyword and get the tweets\n",
    "for keyword in keywords:\n",
    "    search_results = tweepy.Cursor(api.search_tweets, q=keyword, tweet_mode='extended').items(num_tweets)\n",
    "    for tweet in search_results:\n",
    "        # Extract the tweet data\n",
    "        tweet_data = {\n",
    "            'id': tweet.id,\n",
    "            'text': tweet.full_text,\n",
    "            'user_id': tweet.user.id,\n",
    "            'timestamp': tweet.created_at,\n",
    "            'retweet_count': tweet.retweet_count,\n",
    "            'favorite_count': tweet.favorite_count,\n",
    "            'in_reply_to_user_id': tweet.in_reply_to_user_id,\n",
    "            'twt_hashtags' : tweet.entities['hashtags'],\n",
    "            'user_id': tweet.user.id,\n",
    "            'user_name': tweet.user.name,\n",
    "            'followers_count': tweet.user.followers_count,\n",
    "            'friends_count': tweet.user.friends_count\n",
    "        }\n",
    "        # Append the tweet data to the list of tweets\n",
    "        tweets.append(tweet_data)\n",
    "        num_retrieved += 1\n",
    "        # Backup the data to a CSV file every backup_interval tweets\n",
    "        if num_retrieved % backup_interval == 0:\n",
    "            df = pd.DataFrame(tweets)\n",
    "            df.to_csv(output_file, index=False)\n",
    "            print(f\"Backup complete at {time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Retrieved {num_retrieved} tweets for keyword '{keyword}'\")\n",
    "    # Backup the data to a CSV file after all tweets for a keyword have been retrieved\n",
    "    df = pd.DataFrame(tweets)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"Backup complete at {time.strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dab09837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49029 entries, 0 to 49028\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   49023 non-null  object \n",
      " 1   text                 49009 non-null  object \n",
      " 2   user_id              48999 non-null  object \n",
      " 3   timestamp            48999 non-null  object \n",
      " 4   retweet_count        48999 non-null  float64\n",
      " 5   favorite_count       48989 non-null  float64\n",
      " 6   in_reply_to_user_id  8683 non-null   object \n",
      " 7   twt_hashtags         48999 non-null  object \n",
      " 8   user_name            48997 non-null  object \n",
      " 9   followers_count      48999 non-null  float64\n",
      " 10  friends_count        48989 non-null  float64\n",
      "dtypes: float64(4), object(7)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"twitter_1.csv\")\n",
    "\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "590f5ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30076 entries, 0 to 30075\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   30076 non-null  object \n",
      " 1   text                 30076 non-null  object \n",
      " 2   user_id              30066 non-null  object \n",
      " 3   timestamp            30066 non-null  object \n",
      " 4   retweet_count        30066 non-null  float64\n",
      " 5   favorite_count       30066 non-null  float64\n",
      " 6   in_reply_to_user_id  6225 non-null   object \n",
      " 7   twt_hashtags         30066 non-null  object \n",
      " 8   user_name            30066 non-null  object \n",
      " 9   followers_count      30066 non-null  float64\n",
      " 10  friends_count        30056 non-null  float64\n",
      "dtypes: float64(4), object(7)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"twitter_56.csv\")\n",
    "\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "81046da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2]).reset_index(drop=True)\n",
    "df.to_csv(\"twitter_concat.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6486bd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 79105 entries, 0 to 79104\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   79099 non-null  object \n",
      " 1   text                 79085 non-null  object \n",
      " 2   user_id              79065 non-null  object \n",
      " 3   timestamp            79065 non-null  object \n",
      " 4   retweet_count        79065 non-null  float64\n",
      " 5   favorite_count       79055 non-null  float64\n",
      " 6   in_reply_to_user_id  14908 non-null  object \n",
      " 7   twt_hashtags         79065 non-null  object \n",
      " 8   user_name            79063 non-null  object \n",
      " 9   followers_count      79065 non-null  float64\n",
      " 10  friends_count        79045 non-null  float64\n",
      "dtypes: float64(4), object(7)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6980256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create keywords for each coin in top_coins\n",
    "coin_keywords = {\n",
    "    'Bitcoin': ['bitcoin', 'btc', 'bitcoinprice'],\n",
    "    'Ethereum': ['ethereum', 'eth', 'ethprice'],\n",
    "    'BNB': ['bnb', 'binance', 'binancecoin'],\n",
    "    'XRP': ['xrp', 'ripple', 'xrpprice'],\n",
    "    'Cardano': ['cardano', 'ada', 'adaprice'],\n",
    "    'Dogecoin': ['dogecoin', 'doge', 'dogeprice'],\n",
    "    'Polygon': ['polygon', 'matic', 'maticprice'],\n",
    "    'Solana': ['solana', 'sol', 'solprice'],\n",
    "    'Polkadot': ['polkadot', 'dot', 'dotprice'],\n",
    "    'Shiba Inu': ['shibainu', 'shib', 'shibprice'],\n",
    "    'TRON': ['tron', 'trx', 'trxprice'],\n",
    "    'Litecoin': ['litecoin', 'ltc', 'ltcprice'],\n",
    "    'Avalanche': ['avalanche', 'avax', 'avaxprice'],\n",
    "    'Dai': ['dai', 'dai', 'daiprice'],\n",
    "    'Uniswap': ['uniswap', 'uni', 'uniprice'],\n",
    "    'Wrapped Bitcoin': ['wrapped bitcoin', 'wbtc', 'wbtcprice'],\n",
    "    'Chainlink': ['chainlink', 'link', 'linkprice'],\n",
    "    'Cosmos': ['cosmos', 'atom', 'atomprice'],\n",
    "    'UNUS SED LEO': ['unus sed leo', 'leo', 'leoprice'],\n",
    "    'Toncoin': ['toncoin', 'ton', 'tonprice'],\n",
    "    'Ethereum Classic': ['ethereum classic', 'etc', 'etcprice'],\n",
    "    'Monero': ['monero', 'xmr', 'xmrprice'],\n",
    "    'OKB': ['okb', 'okb', 'okbprice'],\n",
    "    'Bitcoin Cash': ['bitcoin cash', 'bch', 'bchprice'],\n",
    "    'Stellar': ['stellar', 'xlm', 'xlmprice'],\n",
    "    'Filecoin': ['filecoin', 'fil', 'filprice'],\n",
    "    'Aptos': ['aptos', 'aptos', 'aptosprice'],\n",
    "    'TrueUSD': ['trueusd', 'tusd', 'tusdprice'],\n",
    "    'Lido DAO': ['lido dao', 'ldo', 'ldoprice'],\n",
    "    'Hedera': ['hedera', 'hbar', 'hbarprice'],\n",
    "    'Cronos': ['cronos', 'cro', 'croprice'],\n",
    "    'NEAR Protocol': ['near protocol', 'near', 'nearprice'],\n",
    "    'VeChain': ['vechain', 'vet', 'vetprice'],\n",
    "    'Algorand': ['algorand', 'algo', 'algoprice'],\n",
    "    'Quant': ['quant', 'qnt', 'qntprice'],\n",
    "    'Internet Computer': ['internet computer', 'icp', 'icpprice'],\n",
    "    'ApeCoin': ['apecoin', 'apecoin', 'apecoinprice'],\n",
    "    'Stacks': ['stacks', 'stx', 'stxprice'],\n",
    "    'The Graph': ['the graph', 'grt', 'grtprice'],\n",
    "    'Fantom': ['fantom', 'ftm', 'ftmprice'],\n",
    "    'EOS': ['eos', 'eos', 'eosprice'],\n",
    "    'BitDAO': ['bitdao', 'bit', 'bitprice'],\n",
    "    'Decentraland': ['decentraland', 'mana', 'manaprice'],\n",
    "    'Aave': ['aave', 'aaveprice'],\n",
    "    'MultiversX': ['multiversx', 'mvx', 'mvxprice'],\n",
    "    'Tezos': ['tezos', 'xtz', 'xtzprice'],\n",
    "    'Flow': ['flow', 'flowprice'],\n",
    "    'Immutable': ['immutable', 'blockchain', 'immutablex', 'imx', 'imxprice'],\n",
    "    'Conflux': ['conflux', 'cfx', 'cfxprice'],\n",
    "    'Theta Network': ['theta', 'thetanetwork', 'thetafuel', 'tfuel', 'tfuelprice'],\n",
    "    'Axie Infinity': ['axieinfinity', 'axs', 'axsprice'],\n",
    "    'The Sandbox': ['sandbox', 'sandboxgame', 'sand', 'sandprice'],\n",
    "    'KuCoin Token': ['kucoin', 'kcs', 'kcsprice'],\n",
    "    'Pax Dollar': ['paxdollar', 'usdp', 'usdprice'],\n",
    "    'Neo': ['neo', 'neo3', 'neo3.0', 'neo3.0price'],\n",
    "    'Chiliz': ['chiliz', 'chz', 'chzprice'],\n",
    "    'Optimism': ['optimism', 'optimisml2', 'optimisml2price'],\n",
    "    'Rocket Pool': ['rocketpool', 'rpl', 'rplprice'],\n",
    "    'Terra Classic': ['terraclassic', 'trcl', 'trclprice'],\n",
    "    'Curve DAO Token': ['curvedao', 'crv', 'crvprice'],\n",
    "    'USDD': ['usdd', 'usddprice'],\n",
    "    'Klaytn': ['klaytn', 'klay', 'klayprice'],\n",
    "    'Mina': ['mina', 'mina', 'mina'],\n",
    "    'Bitcoin SV': ['bitcoinsv', 'bsv', 'bsvprice'],\n",
    "    'Synthetix': ['synthetix', 'snx', 'snxprice'],\n",
    "    'PancakeSwap': ['pancakeswap', 'cake', 'cakeprice'],\n",
    "    'GMX': ['gmexico', 'gmx', 'gmxprice'],\n",
    "    'Maker': ['maker', 'mkr', 'mkrprice'],\n",
    "    'Huobi Token': ['huobi', 'ht', 'htprice'],\n",
    "    'Dash': ['dash', 'dash', 'dashprice'],\n",
    "    'Gemini Dollar': ['geminidollar', 'gusd', 'gusdprice'],\n",
    "    'eCash': ['ecash', 'xec', 'xecprice'],\n",
    "    'IOTA': ['iota', 'miota', 'iotaprice'],\n",
    "    'Frax Share': ['frax', 'fxs', 'fxsprice'],\n",
    "    'BitTorrent(New)': ['bittorrent', 'btt', 'bttprice'],\n",
    "    'Zcash': ['zcash', 'zec', 'zecprice'],\n",
    "    'GateToken': ['gateio', 'gt', 'gtprice'],\n",
    "    'SingularityNET': ['singularitynet', 'agi', 'agiprice'],\n",
    "    'XDC Network': ['xdc', 'xdc', 'xdcprice'],\n",
    "    'PAX Gold': ['paxgold', 'paxg', 'paxgprice'],\n",
    "    'Trust Wallet Token': ['trustwallet', 'twtprice'],\n",
    "    'Render Token': ['render token', 'rndr', 'rndrprice'],\n",
    "    'THORChain': ['thorchain', 'rune', 'runeprice'],\n",
    "    'Loopring': ['loopring', 'lrc', 'lrcprice'],\n",
    "    'Zilliqa': ['zilliqa', 'zil', 'zilprice'],\n",
    "    '1inch Network': ['1inch network', '1inch', '1inchprice'],\n",
    "    'Kava': ['kava', 'kava.io', 'kavaprice'],\n",
    "    'Convex Finance': ['convex finance', 'cvx', 'cvxprice'],\n",
    "    'Fei USD': ['fei usd', 'fei', 'feiprice'],\n",
    "    'Osmosis': ['osmosis', 'osmo', 'osmoprice'],\n",
    "    'Enjin Coin': ['enjin coin', 'enj', 'enjprice'],\n",
    "    'Casper': ['casper', 'cas', 'casprice'],\n",
    "    'dYdX': ['dydx', 'dydxprotocol', 'dydxprice'],\n",
    "    'MAGIC': ['magic', 'magic internet money', 'magicprice'],\n",
    "    'Mask Network': ['mask network', 'mask', 'maskprice'],\n",
    "    'ssv.network': ['ssv.network', 'ssv', 'ssvprice'],\n",
    "    'Threshold': ['threshold', 'thd', 'thdprice']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c2fb68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_coins = list(coin_keywords.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c24360e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'coin_keywords' (dict)\n",
      "Stored 'top_coins' (list)\n"
     ]
    }
   ],
   "source": [
    "%store coin_keywords top_coins"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
